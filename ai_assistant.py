import logging
from openai import AsyncOpenAI
from typing import Optional, Dict, Any
from config import (
    AI_API_KEY,
    AI_MODEL,
    AI_ENABLED,
    AI_MAX_TOKENS,
    AI_TEMPERATURE,
    FAQ_QUESTIONS,
    TRANSLATIONS,
)

logger = logging.getLogger(__name__)


def ai_wants_to_escalate(ai_response: str) -> bool:
    """
    ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, Ñ…Ğ¾Ñ‡ĞµÑ‚ Ğ»Ğ¸ AI Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ñƒ.
    Ğ•ÑĞ»Ğ¸ AI Ğ½Ğ°Ğ¿Ğ¸ÑĞ°Ğ» Ğ¿Ñ€Ğ¾ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ñƒ/ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ğµ - Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ True.
    """
    response_lower = ai_response.lower()
    
    escalation_phrases = [
        "Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ",
        "Ğ¿ĞµÑ€ĞµĞ´Ğ°Ğ¼",
        "ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ",
        "ÑƒÑ‚Ğ¾Ñ‡Ğ½",
        "ĞºĞ¾Ğ»Ğ»ĞµĞ³",
        "ĞºĞ¾Ğ»Ğ»ĞµĞ³Ğµ",
        "ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚",
        "Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€",
        "Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½",
        "Ñ€Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€",
        "Ğ·Ğ°Ğ½Ğ¸Ğ¼Ğ°ĞµĞ¼ÑÑ",
        "Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼",
        "Ğ²ĞµÑ€Ğ½Ñ‘Ğ¼ÑÑ",
        "Ñ€ĞµÑˆĞµĞ½Ğ¸ĞµĞ¼"
    ]
    
    for phrase in escalation_phrases:
        if phrase in response_lower:
            logger.info(f"ğŸ”„ AI wants to escalate: detected '{phrase}' in response")
            return True
    
    return False


def detect_strong_emotion(message: str) -> bool:
    """
    ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ñ… ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¹, Ğ¼Ğ°Ñ‚Ğ° Ğ¸Ğ»Ğ¸ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼.
    Ğ•ÑĞ»Ğ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ - Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ»ÑƒÑ‡ÑˆĞµ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‚ÑŒ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ñƒ.
    """
    message_lower = message.lower()
    
    # ĞœĞ°Ñ‚ Ğ¸ Ğ³Ñ€ÑƒĞ±Ğ°Ñ Ğ»ĞµĞºÑĞ¸ĞºĞ°
    profanity = [
        "Ğ±Ğ»ÑÑ‚ÑŒ", "Ğ±Ğ»Ñ", "Ğ±Ğ»ÑĞ´ÑŒ", "ĞµĞ±Ğ°Ñ‚ÑŒ", "ĞµĞ±Ğ°Ğ»", "Ñ…ÑƒĞ¹", "Ğ¿Ğ¸Ğ·Ğ´", "ÑÑƒĞºĞ°", 
        "Ğ³Ğ°Ğ²Ğ½Ğ¾", "Ğ³Ğ¾Ğ²Ğ½Ğ¾", "Ğ´ĞµÑ€ÑŒĞ¼", "fuck", "shit", "damn", "asshole"
    ]
    
    # Ğ¡Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¸
    strong_negative = [
        "Ğ½ĞµĞ½Ğ°Ğ²Ğ¸Ğ¶Ñƒ", "Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‚Ğ¸Ñ‚ĞµĞ»ÑŒĞ½", "ÑƒĞ¶Ğ°ÑĞ½", "ĞºĞ¾ÑˆĞ¼Ğ°Ñ€", "Ğ¾Ñ‚ÑÑ‚Ğ¾Ğ¹",
        "Ğ¼Ğ¾ÑˆĞµĞ½Ğ½Ğ¸Ğº", "Ñ€Ğ°Ğ·Ğ²Ğ¾Ğ´", "Ğ¾Ğ±Ğ¼Ğ°Ğ½", "ÑƒĞºÑ€Ğ°Ğ»", "Ğ¶Ğ°Ğ»Ğ¾Ğ±", "ÑÑƒĞ´",
        "Ğ²Ğ¾Ğ·Ğ¼ÑƒÑ‰Ñ‘Ğ½", "Ğ²Ğ¾Ğ·Ğ¼ÑƒÑ‰ĞµĞ½", "Ğ¶Ğ´Ñƒ ÑƒĞ¶Ğµ", "Ñ‡Ğ°ÑĞ¾Ğ²", "Ğ´Ğ½ĞµĞ¹", "Ğ½ĞµĞ´ĞµĞ»",
        "Ğ±Ñ€ĞµĞ´", "Ğ´ĞµĞ±Ğ¸Ğ»"
    ]
    
    # Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‰Ğ¸Ğµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ° (Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ¸Ğ· Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ)
    technical_issues = [
        "Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ¸Ñ‚ĞµÑÑŒ Ğ² Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºÑƒ",
        "Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ¸Ñ‚ĞµÑÑŒ Ğ² ÑĞ»ÑƒĞ¶Ğ±Ñƒ",
        "Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ¸Ñ‚ĞµÑÑŒ Ğº Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞµ",
        "ÑĞ²ÑĞ¶Ğ¸Ñ‚ĞµÑÑŒ Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹",
        "Ğ¾ÑˆĞ¸Ğ±ĞºĞ°",
        "Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ²Ñ‹Ğ²ĞµÑÑ‚Ğ¸",
        "Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ½Ğ° Ğ²Ñ‹Ğ²Ğ¾Ğ´",
        "Ğ½Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ÑÑ",
        "Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ²Ñ‹Ğ²Ğ¾Ğ´"
    ]
    
    # Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¿Ñ€Ğ¾ Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ° (Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ñ…Ğ¾Ñ‡ĞµÑ‚ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚ÑŒ Ñ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ¾Ğ¼)
    waiting_questions = [
        "ĞºĞ°Ğº ÑĞºĞ¾Ñ€Ğ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑ‚",
        "ĞºĞ¾Ğ³Ğ´Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑ‚",
        "ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¶Ğ´Ğ°Ñ‚ÑŒ",
        "ĞºĞ¾Ğ³Ğ´Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚",
        "ĞºĞ¾Ğ³Ğ´Ğ° Ñ€ĞµÑˆĞ°Ñ‚",
        "Ğ´Ğ¾Ğ»Ğ³Ğ¾ Ğ¶Ğ´Ğ°Ñ‚ÑŒ",
        "ĞºĞ¾Ğ³Ğ´Ğ° Ñ€Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€ÑÑ‚"
    ]
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¼Ğ°Ñ‚
    for word in profanity:
        if word in message_lower:
            logger.info(f"ğŸ”¥ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½ Ğ¼Ğ°Ñ‚ Ğ² ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¸: '{word}'")
            return True
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ (Ñ‚Ñ€ĞµĞ±ÑƒÑÑ‚ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°)
    for phrase in technical_issues:
        if phrase in message_lower:
            logger.info(f"âš ï¸ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ° Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: '{phrase}'")
            return True
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¿Ñ€Ğ¾ Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ (Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ñ…Ğ¾Ñ‡ĞµÑ‚ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°)
    for phrase in waiting_questions:
        if phrase in message_lower:
            logger.info(f"â° ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ ÑĞ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¾ Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ: '{phrase}'")
            return True
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞ¸Ğ»ÑŒĞ½Ñ‹Ğµ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¸ (Ğ¼Ğ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼ 2 ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ½Ğ¸Ñ)
    negative_count = sum(1 for word in strong_negative if word in message_lower)
    if negative_count >= 2:
        logger.info(f"ğŸ˜¡ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ° ÑĞ¸Ğ»ÑŒĞ½Ğ°Ñ Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ ÑĞ¼Ğ¾Ñ†Ğ¸Ñ (count={negative_count})")
        return True
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ÑÑÑ‰Ğ¸ĞµÑÑ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ (Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°Ğº Ñ€Ğ°Ğ·Ğ´Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ)
    if "ÑƒĞ¶Ğµ" in message_lower and any(time_word in message_lower for time_word in ["Ñ‡Ğ°Ñ", "Ğ´ĞµĞ½ÑŒ", "Ğ½ĞµĞ´ĞµĞ»", "ÑÑƒÑ‚ĞºĞ¸"]):
        logger.info(f"â° ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ´Ğ¾Ğ»Ğ³Ğ¾ Ğ¶Ğ´ĞµÑ‚ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ")
        return True
    
    return False


class AIAssistant:
    """Ğ˜Ğ˜-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°Ğ¼"""
    
    def __init__(self):
        print(f"[DEBUG] Initializing AI Assistant... AI_ENABLED={AI_ENABLED}, API_KEY={'SET' if AI_API_KEY else 'EMPTY'}")
        self.enabled = AI_ENABLED
        self.client = None
        if self.enabled and AI_API_KEY:
            self.client = AsyncOpenAI(api_key=AI_API_KEY)
            logger.info(f"âœ… AI Assistant initialized with model: {AI_MODEL}")
            print(f"[DEBUG] AI Assistant initialized successfully with model: {AI_MODEL}")
        else:
            logger.warning(f"âš ï¸  AI Assistant is disabled (enabled={AI_ENABLED}, api_key={'set' if AI_API_KEY else 'empty'})")
            print(f"[DEBUG] AI Assistant NOT initialized: enabled={AI_ENABLED}, api_key={'set' if AI_API_KEY else 'empty'}")
    
    def _build_system_prompt(self, lang: str = "ru") -> str:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµÑ‚ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ñ Ğ±Ğ°Ğ·Ğ¾Ğ¹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹"""
        
        # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ
        system_prompt = f"""Ğ¢Ñ‹ - Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ ÑĞ»ÑƒĞ¶Ğ±Ñ‹ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¸ Majestic Game Bot. ĞĞ±Ñ‰Ğ°Ğ¹ÑÑ ĞºĞ°Ğº Ğ¶Ğ¸Ğ²Ğ¾Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº.

ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜ Ğ’ĞĞ–ĞĞ - Ğ—ĞĞŸĞ Ğ•Ğ©Ğ•ĞĞĞ«Ğ• Ğ¤Ğ ĞĞ—Ğ«:
ğŸš« "Ğ¯ Ğ·Ğ´ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ"
ğŸš« "ĞŸĞ¾ÑÑ‚Ğ°Ñ€Ğ°ÑÑÑŒ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ"
ğŸš« "Ğ£Ñ‚Ğ¾Ñ‡Ğ½Ğ¸Ñ‚Ğµ Ğ¿Ğ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°"
ğŸš« "ĞšĞ°ĞºĞ°Ñ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°"
ğŸš« "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½ĞµĞµ"
ğŸš« "ĞšĞ°ĞºĞ¾Ğ¹ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ Ğ¿Ğ¾Ğ´Ğ°Ñ€Ğ¾Ğº"
ğŸš« ĞĞ• Ğ·Ğ°Ğ´Ğ°Ğ²Ğ°Ğ¹ ÑƒÑ‚Ğ¾Ñ‡Ğ½ÑÑÑ‰Ğ¸Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² ĞµÑĞ»Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° ĞĞ§Ğ•Ğ’Ğ˜Ğ”ĞĞ!

Ğ¢Ğ’ĞĞ¯ Ğ ĞĞ›Ğ¬:
- Ğ¢Ñ‹ ĞŸĞ•Ğ Ğ’ĞĞ¯ Ğ»Ğ¸Ğ½Ğ¸Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¸
- ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ½Ğ° Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¸Ğ· FAQ
- ĞŸĞ¸ÑˆĞ¸ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾ (1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ)
- Ğ¯Ğ·Ñ‹Ğº: {lang}

ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ ĞĞ¢Ğ’Ğ•Ğ¢ĞĞ’:
1. ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¸Ğ· FAQ â†’ Ğ´Ğ°Ğ¹ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚
2. Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ "ĞºĞ°Ğº ÑĞºĞ¾Ñ€Ğ¾", "ĞºĞ¾Ğ³Ğ´Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑ‚" â†’ Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸ Ñ‡Ñ‚Ğ¾ Ğ·Ğ°ÑĞ²ĞºĞ° ÑƒĞ¶Ğµ Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ
3. ĞĞ• Ğ·Ğ°Ğ´Ğ°Ğ²Ğ°Ğ¹ ÑƒÑ‚Ğ¾Ñ‡Ğ½ÑÑÑ‰Ğ¸Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² - Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ¿Ğ¾ ÑÑƒÑ‚Ğ¸!
4. Ğ­Ğ¼Ğ¾Ğ´Ğ·Ğ¸: ĞĞ• Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ÑĞ¾Ğ²ÑĞµĞ¼
5. Ğ•ÑĞ»Ğ¸ Ğ½Ğµ Ğ·Ğ½Ğ°ĞµÑˆÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° â†’ Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸: "Ğ—Ğ°Ğ½Ğ¸Ğ¼Ğ°ĞµĞ¼ÑÑ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğ²Ğ°ÑˆĞµĞ¹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹. Ğ¡ĞºĞ¾Ñ€Ğ¾ Ğ²ĞµÑ€Ğ½Ñ‘Ğ¼ÑÑ Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸ĞµĞ¼."

Ğ‘ĞĞ—Ğ Ğ—ĞĞĞĞ˜Ğ™:
"""
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ FAQ Ğ² Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚
        for topic, questions in FAQ_QUESTIONS.items():
            if lang in questions:
                topic_name = TRANSLATIONS[lang]["topics"].get(topic, topic)
                system_prompt += f"\n\nğŸ“Œ {topic_name.upper()}:\n"
                
                lang_questions = questions[lang]
                for i in range(1, 10):
                    q_key = f"question{i}"
                    a_key = f"answer{i}"
                    if q_key in lang_questions and a_key in lang_questions:
                        question = lang_questions[q_key]
                        answer = lang_questions[a_key]
                        if answer:  # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚
                            system_prompt += f"\nĞ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: {question}\nĞÑ‚Ğ²ĞµÑ‚: {answer}\n"
        
        system_prompt += """

ĞŸĞ Ğ˜ĞœĞ•Ğ Ğ« ĞĞ¢Ğ’Ğ•Ğ¢ĞĞ’:
- ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ: "ĞšĞ°Ğº Ğ¿Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ?" â†’ Ğ”Ğ°Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ Ğ¸Ğ· Ğ±Ğ°Ğ·Ñ‹ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹
- ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ: "ĞĞµ Ğ¿Ñ€Ğ¸ÑˆĞ»Ğ¸ Ğ´ĞµĞ½ÑŒĞ³Ğ¸" â†’ "Ğ¢Ñ€Ğ°Ğ½Ğ·Ğ°ĞºÑ†Ğ¸Ğ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ Ğ´Ğ¾ 15 Ğ¼Ğ¸Ğ½ÑƒÑ‚. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ Ğ¿Ğ¾Ğ·Ğ¶Ğµ."
- ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ: "ĞšĞ°Ğº ÑĞºĞ¾Ñ€Ğ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑ‚ Ğ¼Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ?" â†’ "Ğ’Ğ°ÑˆĞµ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ ÑƒĞ¶Ğµ Ğ² Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ. Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ñ‚ Ğ¾Ñ‚ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¸."
- ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ: "its wrong me have 2 accounts only" â†’ "Ğ—Ğ°Ğ½Ğ¸Ğ¼Ğ°ĞµĞ¼ÑÑ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğ²Ğ°ÑˆĞµĞ¹ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹. Ğ¡ĞºĞ¾Ñ€Ğ¾ Ğ²ĞµÑ€Ğ½Ñ‘Ğ¼ÑÑ Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸ĞµĞ¼."

Ğ’ĞĞ–ĞĞ: ĞšĞ¾Ğ³Ğ´Ğ° Ğ¿Ğ¸ÑˆĞµÑˆÑŒ Ğ¿Ñ€Ğ¾ Ğ¸Ğ·ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ - ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ¿ĞµÑ€ĞµĞ´Ğ°ÑÑ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ñƒ!
"""
        
        return system_prompt
    
    async def get_ai_response(
        self,
        user_message: str,
        lang: str = "ru",
        context: Optional[Dict[str, Any]] = None
    ) -> Optional[str]:
        """
        ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ Ğ˜Ğ˜ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
        
        Args:
            user_message: ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
            lang: ÑĞ·Ñ‹Ğº Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
            context: Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ (Ñ‚ĞµĞ¼Ğ°, Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¸ Ñ‚.Ğ´.)
        
        Returns:
            ĞÑ‚Ğ²ĞµÑ‚ Ğ˜Ğ˜ Ğ¸Ğ»Ğ¸ None Ğ² ÑĞ»ÑƒÑ‡Ğ°Ğµ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸
        """
        logger.info(f"ğŸ“¥ get_ai_response called: message='{user_message[:50]}...', lang={lang}, context={context}")
        
        if not self.enabled:
            logger.warning("âš ï¸  AI is disabled, skipping response generation")
            return None
        
        if not AI_API_KEY:
            logger.error("âŒ AI API key is not configured")
            return None
        
        if not self.client:
            logger.error("âŒ OpenAI client is not initialized")
            return None
        
        try:
            logger.info(f"ğŸ”¨ Building system prompt for lang={lang}...")
            system_prompt = self._build_system_prompt(lang)
            logger.info(f"âœ… System prompt built, length={len(system_prompt)}")
            
            # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
            if context:
                topic = context.get("topic")
                if topic:
                    topic_name = TRANSLATIONS[lang]["topics"].get(topic, topic)
                    system_prompt += f"\n\nĞ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ñ‚ĞµĞ¼Ğ° Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ: {topic_name}"
                    logger.info(f"ğŸ“Œ Added topic context: {topic_name}")
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº API
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ]
            
            logger.info(f"ğŸŒ Requesting AI response from OpenAI (model={AI_MODEL})...")
            logger.info(f"ğŸ“ User message: {user_message}")
            
            response = await self.client.chat.completions.create(
                model=AI_MODEL,
                messages=messages,
                max_tokens=AI_MAX_TOKENS,
                temperature=AI_TEMPERATURE,
            )
            
            ai_message = response.choices[0].message.content.strip()
            logger.info(f"âœ… AI response received! Length={len(ai_message)}")
            logger.info(f"ğŸ’¬ AI response preview: {ai_message[:100]}...")
            
            return ai_message
        
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ Error in get_ai_response: {e}", exc_info=True)
            if "authentication" in error_msg.lower() or "api_key" in error_msg.lower():
                logger.error("ğŸ”‘ OpenAI Authentication failed - check your API key")
            elif "rate" in error_msg.lower() or "limit" in error_msg.lower():
                logger.warning("â±ï¸  OpenAI rate limit exceeded")
            else:
                logger.error(f"ğŸ’¥ OpenAI API error: {e}")
            return None
        except Exception as e:
            logger.error(f"Unexpected error in AI response generation: {e}", exc_info=True)
            return None
    
    def should_escalate_to_human(self, ai_response: str) -> bool:
        """
        ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚, Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ»Ğ¸ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ñƒ
        
        Args:
            ai_response: Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ˜Ğ˜
        
        Returns:
            True ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‚ÑŒ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ñƒ
        """
        escalation_keywords = [
            "Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€",
            "ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚",
            "Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğº",
            "ÑĞ²ÑĞ¶",
            "Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ",
            "Ğ½Ğµ ÑƒĞ²ĞµÑ€ĞµĞ½",
            "Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒÑ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒÑÑ",
        ]
        
        ai_response_lower = ai_response.lower()
        return any(keyword in ai_response_lower for keyword in escalation_keywords)
    
    async def analyze_sentiment(self, user_message: str, lang: str = "ru") -> str:
        """
        ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
        
        Args:
            user_message: ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
            lang: ÑĞ·Ñ‹Ğº
        
        Returns:
            Ğ¢Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ: "positive", "neutral", "negative"
        """
        if not self.enabled or not AI_API_KEY or not self.client:
            return "neutral"
        
        try:
            prompt = f"""ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ñ‚Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ.
ĞÑ‚Ğ²ĞµÑ‚ÑŒ Ğ¾Ğ´Ğ½Ğ¸Ğ¼ ÑĞ»Ğ¾Ğ²Ğ¾Ğ¼: positive, neutral Ğ¸Ğ»Ğ¸ negative.

Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ: {user_message}

Ğ¢Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ:"""
            
            response = await self.client.chat.completions.create(
                model=AI_MODEL,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=10,
                temperature=0.3,
            )
            
            sentiment = response.choices[0].message.content.strip().lower()
            if sentiment in ["positive", "neutral", "negative"]:
                return sentiment
            return "neutral"
        
        except Exception as e:
            logger.error(f"Error analyzing sentiment: {e}")
            return "neutral"
    
    async def generate_thread_title(self, user_message: str, topic: str, lang: str = "ru") -> str:
        """
        Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ ĞºÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚ĞµĞ¼Ñ‹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
        
        Args:
            user_message: Ğ¿ĞµÑ€Ğ²Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
            topic: Ñ‚ĞµĞ¼Ğ° Ñ‚Ğ¸ĞºĞµÑ‚Ğ°
            lang: ÑĞ·Ñ‹Ğº
            
        Returns:
            ĞšÑ€Ğ°Ñ‚ĞºĞ¾Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ ÑĞ¼Ğ¾Ğ´Ğ·Ğ¸ (Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 50 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²)
        """
        if not self.enabled or not AI_API_KEY or not self.client:
            # Fallback Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ñ Ñ ÑĞ¼Ğ¾Ğ´Ğ·Ğ¸
            emoji_map = {
                "balance": "ğŸ’°",
                "withdrop": "ğŸ",
                "bugs": "ğŸ›",
                "donate": "ğŸ’",
                "cooperation": "ğŸ¤"
            }
            emoji = emoji_map.get(topic, "ğŸ“")
            return f"{emoji} ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ"
        
        try:
            prompt = f"""Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ ĞĞ§Ğ•ĞĞ¬ ĞšĞ ĞĞ¢ĞšĞĞ• Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ñ‚Ğ¸ĞºĞµÑ‚Ğ° Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¸ (Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 5-6 ÑĞ»Ğ¾Ğ²) Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ° ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°.
ĞĞ°Ñ‡Ğ½Ğ¸ Ñ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ÑÑ‰ĞµĞ³Ğ¾ ÑĞ¼Ğ¾Ğ´Ğ·Ğ¸.
Ğ¯Ğ·Ñ‹Ğº: {lang}

ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:
- "Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ¿Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ Ğ±Ğ°Ğ»Ğ°Ğ½Ñ" â†’ "ğŸ’° ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ñ Ğ¿Ğ¾Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸ĞµĞ¼"
- "ĞºĞ°Ğº Ğ²Ñ‹Ğ²ĞµÑÑ‚Ğ¸ Ğ¿Ğ¾Ğ´Ğ°Ñ€ĞºĞ¸" â†’ "ğŸ Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ñ€Ğ¾ Ğ²Ñ‹Ğ²Ğ¾Ğ´"
- "Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ²Ñ…Ğ¾Ğ´Ğµ" â†’ "ğŸ› ĞÑˆĞ¸Ğ±ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ°"
- "Ñ…Ğ¾Ñ‡Ñƒ ÑÑ‚Ğ°Ñ‚ÑŒ Ğ¿Ğ°Ñ€Ñ‚Ğ½ĞµÑ€Ğ¾Ğ¼" â†’ "ğŸ¤ ĞŸĞ°Ñ€Ñ‚Ğ½ĞµÑ€ÑÑ‚Ğ²Ğ¾"

Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°: {user_message[:200]}

ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ (Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 50 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²):"""
            
            response = await self.client.chat.completions.create(
                model=AI_MODEL,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=30,
                temperature=0.7,
            )
            
            title = response.choices[0].message.content.strip()
            
            # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ñƒ
            if len(title) > 50:
                title = title[:47] + "..."
            
            logger.info(f"âœ¨ Generated thread title: '{title}'")
            return title
        
        except Exception as e:
            logger.error(f"Error generating thread title: {e}")
            # Fallback
            emoji_map = {
                "balance": "ğŸ’°",
                "withdrop": "ğŸ",
                "bugs": "ğŸ›",
                "donate": "ğŸ’",
                "cooperation": "ğŸ¤"
            }
            emoji = emoji_map.get(topic, "ğŸ“")
            return f"{emoji} ĞĞ¾Ğ²Ñ‹Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ"


# Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞºĞ·ĞµĞ¼Ğ¿Ğ»ÑÑ€ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ°
ai_assistant = AIAssistant()

